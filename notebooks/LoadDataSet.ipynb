{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\r\n",
                "import math\r\n",
                "from pandas import DataFrame\r\n",
                "import numpy as np\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif\r\n",
                "from datetime import datetime, timedelta, timezone\r\n",
                "import pyodbc\r\n",
                "from sqlalchemy import Column, Date, Integer, String, Numeric, create_engine, Float, inspect, func, MetaData, Table, select, ForeignKey\r\n",
                "from sqlalchemy.ext.declarative import declarative_base\r\n",
                "from sqlalchemy.orm import mapper, registry, Session, relationship\r\n",
                "from sqlalchemy.ext.automap import automap_base\r\n",
                "from sklearn.tree import DecisionTreeClassifier\r\n",
                "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, balanced_accuracy_score \r\n",
                "from sklearn.model_selection import GridSearchCV\r\n",
                "from sklearn.linear_model import LogisticRegression\r\n",
                "from sklearn.preprocessing import LabelEncoder\r\n",
                "from sklearn.base import BaseEstimator\r\n",
                "from sklearn.pipeline import Pipeline\r\n",
                "import scipy\r\n",
                "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
            ],
            "metadata": {
                "azdata_cell_guid": "c3d05f7d-fb65-4e9f-a566-814f74338ed5",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#SQLAlchemy Setup\r\n",
                "def get_engine():\r\n",
                "    SERVER = 'localhost'\r\n",
                "    DATABASE = 'metmast'\r\n",
                "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect=DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};Trusted_Connection=yes;TrustServerCertificate=yes;')\r\n",
                "    return engine\r\n",
                "\r\n",
                "engine = get_engine()\r\n",
                "metadata = MetaData()\r\n",
                "metadata.reflect(bind=engine)\r\n",
                "Base = automap_base(metadata=metadata)\r\n",
                "Base.prepare(autoload_with=engine)\r\n",
                "mapper_registry = registry()"
            ],
            "metadata": {
                "azdata_cell_guid": "531a76dc-cb5a-4556-95e6-f783ece904b2",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#########################################################################################################################################################################################\r\n",
                "#data_meta\r\n",
                "class data_meta:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "data_meta_table= Table('data_meta', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = data_meta,\r\n",
                "    local_table = data_meta_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#feature\r\n",
                "class feature:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"data_meta_id\", Integer, ForeignKey(data_meta.id)),\r\n",
                "            Column(\"name\", String),\r\n",
                "            Column(\"type_\", String),\r\n",
                "            Column(\"description\", String)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "feature_table= Table('feature', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = feature,\r\n",
                "    local_table = feature_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#label\r\n",
                "class label:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"data_meta_id\", Integer, ForeignKey(data_meta.id)),\r\n",
                "            Column(\"name\", String),\r\n",
                "            Column(\"description\", String)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "label_table= Table('label', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = label,\r\n",
                "    local_table = label_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#label_categorical\r\n",
                "class label_categorical:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"label_id\", Integer, ForeignKey(data_meta.id)),\r\n",
                "            Column(\"category\", String),\r\n",
                "            Column(\"description\", String)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "label_categorical_table= Table('label_categorical', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = label_categorical,\r\n",
                "    local_table = label_categorical_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#datapoint_mappings\r\n",
                "class datapoint_mappings:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"data_meta_id\", Integer, ForeignKey(data_meta.id)),\r\n",
                "            Column(\"grouping\", String)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "datapoint_mappings_table= Table('datapoint_mappings', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = datapoint_mappings,\r\n",
                "    local_table = datapoint_mappings_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#datapoint\r\n",
                "class datapoint:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"datapoint_mappings_id\", Integer, ForeignKey(datapoint_mappings.id))\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "datapoint_table= Table('datapoint', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = datapoint,\r\n",
                "    local_table = datapoint_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#datapoint_feature_value_int\r\n",
                "class datapoint_feature_value_int:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"datapoint_id\", Integer, ForeignKey(datapoint.id)),\r\n",
                "            Column(\"feature_id\", Integer, ForeignKey(feature.id)),\r\n",
                "            Column(\"int_\", Integer)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "datapoint_feature_value_int_table= Table('datapoint_feature_value_int', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = datapoint_feature_value_int,\r\n",
                "    local_table = datapoint_feature_value_int_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#datapoint_feature_value_float\r\n",
                "class datapoint_feature_value_float:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"datapoint_id\", Integer, ForeignKey(datapoint.id)),\r\n",
                "            Column(\"feature_id\", Integer, ForeignKey(feature.id)),\r\n",
                "            Column(\"float_\", Float)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "datapoint_feature_value_float_table = Table('datapoint_feature_value_float', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = datapoint_feature_value_float,\r\n",
                "    local_table = datapoint_feature_value_float_table\r\n",
                ")\r\n",
                "#########################################################################################################################################################################################\r\n",
                "#datapoint_feature_value_string\r\n",
                "class datapoint_feature_value_string:\r\n",
                "    pass\r\n",
                "\r\n",
                "# Create columns\r\n",
                "columns = [ Column('id', Integer, primary_key=True),\r\n",
                "            Column(\"datapoint_id\", Integer, ForeignKey(datapoint.id)),\r\n",
                "            Column(\"feature_id\", Integer, ForeignKey(feature.id)),\r\n",
                "            Column(\"string_\", String)\r\n",
                "            ]\r\n",
                "\r\n",
                "# Create table\r\n",
                "metadata = MetaData()\r\n",
                "datapoint_feature_value_string_table= Table('datapoint_feature_value_string', metadata, *columns)\r\n",
                "metadata.create_all(engine)\r\n",
                "\r\n",
                "# Map the class imperatively\r\n",
                "mapper_registry.map_imperatively(\r\n",
                "    class_ = datapoint_feature_value_string,\r\n",
                "    local_table = datapoint_feature_value_string_table\r\n",
                ")"
            ],
            "metadata": {
                "azdata_cell_guid": "9b7b30a4-7f65-436f-90f2-75cb1a6b517e",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#SQLAlchemy Setup\r\n",
                "def get_engine():\r\n",
                "    SERVER = 'localhost'\r\n",
                "    DATABASE = 'metmast'\r\n",
                "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect=DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};Trusted_Connection=yes;TrustServerCertificate=yes;')\r\n",
                "    return engine"
            ],
            "metadata": {
                "azdata_cell_guid": "88d57a90-1aaa-4e38-8bf5-c77c173bffc7",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#Loading Data\r\n",
                "failures_2016 = pd.read_csv(r\"C:\\Raw Data\\failures-2016.csv\", sep=\";\")\r\n",
                "failures_2017 = pd.read_csv(r\"C:\\Raw Data\\failures-2017.csv\", sep=\";\")\r\n",
                "metmast_2016 = pd.read_csv(r\"C:\\Raw Data\\metmast-2016.csv\", sep=\";\")\r\n",
                "metmast_2017 = pd.read_csv(r\"C:\\Raw Data\\metmast-2017.csv\", sep=\";\")\r\n",
                "signals_2016 = pd.read_csv(r\"C:\\Raw Data\\signals-2016.csv\", sep=\";\")\r\n",
                "signals_2017 = pd.read_csv(r\"C:\\Raw Data\\signals-2017.csv\", sep=\";\")"
            ],
            "metadata": {
                "azdata_cell_guid": "8079c9ac-b15f-452d-95a3-d860e2b17c49",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "# Signale beider Jahre kombinieren\r\n",
                "signals = pd.concat([signals_2016, signals_2017])\r\n",
                "\r\n",
                "turbine_names = signals[\"Turbine_ID\"].unique()\r\n",
                "\r\n",
                "def create_df_for_each_turbine(signals):\r\n",
                "    turbine_dfs = list();\r\n",
                "\r\n",
                "    for turbine in turbine_names:\r\n",
                "        turbine_df = signals[signals[\"Turbine_ID\"] == turbine]\r\n",
                "        turbine_df = turbine_df.sort_values(\"Timestamp\")\r\n",
                "        turbine_df = turbine_df.reset_index(drop=True)\r\n",
                "        turbine_dfs.append(turbine_df)\r\n",
                "\r\n",
                "    return turbine_dfs\r\n",
                "\r\n",
                "turbine_dfs = create_df_for_each_turbine(signals)\r\n",
                "\r\n",
                "#Zusammenführen und sortieren\r\n",
                "metmast = pd.concat([metmast_2016, metmast_2017])\r\n",
                "metmast = metmast.sort_values(\"Timestamp\")\r\n",
                "\r\n",
                "# drop broken met data\r\n",
                "metmast = metmast.drop([\"Min_Winddirection2\", \"Max_Winddirection2\", \"Avg_Winddirection2\", \"Var_Winddirection2\"], axis=1)\r\n",
                "\r\n",
                "# Fill met data\r\n",
                "metmast = metmast.fillna(method = \"ffill\")\r\n",
                "metmast = metmast.fillna(method = \"bfill\")\r\n",
                "metmast.isna().sum().sum()\r\n",
                "\r\n",
                "failures = pd.concat([failures_2016, failures_2017])\r\n",
                "\r\n",
                "#Mergen\r\n",
                "def JoinMetamast(df:pd.DataFrame):\r\n",
                "    df = df.fillna(method = \"ffill\")\r\n",
                "    df = df.fillna(method = \"bfill\")\r\n",
                "    df = pd.merge(df, metmast, on=\"Timestamp\", how=\"left\")\r\n",
                "    df = df.fillna(method = \"ffill\")\r\n",
                "    df = df.fillna(method = \"bfill\")\r\n",
                "    df.isna().sum().sum()\r\n",
                "    return df\r\n",
                "\r\n",
                "merged = list()\r\n",
                "for turbine_df in turbine_dfs:\r\n",
                "    merged.append(JoinMetamast(turbine_df))\r\n",
                "merged_df = pd.concat(merged)\r\n",
                "\r\n",
                "failures_gearbox = failures[failures[\"Component\"] == \"GEARBOX\"]\r\n",
                "failures_gearbox.reset_index(drop=True, inplace=True)"
            ],
            "metadata": {
                "azdata_cell_guid": "f7981c11-f86f-4d5d-878b-c7bbeef195b4",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#Util Functions\r\n",
                "def get_round_minute_diff(datetime_in: datetime) -> timedelta:\r\n",
                "    min = datetime_in.minute\r\n",
                "    rounded_min = round(min, -1)\r\n",
                "    diff = rounded_min - min\r\n",
                "    return timedelta(minutes=diff)\r\n",
                "\r\n",
                "def convert_round_minute_to_time(datetime_in: datetime) -> datetime:\r\n",
                "    td = get_round_minute_diff(datetime_in)\r\n",
                "    return datetime_in + td"
            ],
            "metadata": {
                "azdata_cell_guid": "b98ad47e-87dd-433f-92e9-5dca69638266",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "days_lookback = 90\r\n",
                "mins_per_class = 24 * 60 / 10\r\n",
                "ten_mins_of_n_days = int(24 * 60 * days_lookback / 10) \r\n",
                "target_name = \"Class\"\r\n",
                "\r\n",
                "def GetClass(i:int)->int:\r\n",
                "    return math.floor(i/mins_per_class)\r\n",
                "\r\n",
                "def create_failure_list() -> pd.DataFrame:\r\n",
                "    failure_list = []\r\n",
                "    for i, failure in enumerate(failures_gearbox):\r\n",
                "        turbine_id = str(failures_gearbox[\"Turbine_ID\"][i])\r\n",
                "        failure_ts = str(failures_gearbox[\"Timestamp\"][i])\r\n",
                "        failure_datetime = datetime.fromisoformat(failure_ts)\r\n",
                "        rounded_datetime = convert_round_minute_to_time(failure_datetime)\r\n",
                "        for j in range(ten_mins_of_n_days):\r\n",
                "            delta = timedelta(minutes=j*10)\r\n",
                "            new_datetime = rounded_datetime - delta\r\n",
                "            datetime_formated = new_datetime.replace(tzinfo=timezone.utc)\r\n",
                "            failure_list.append([turbine_id, datetime_formated.isoformat(), GetClass(j)])    \r\n",
                "    failure_df = pd.DataFrame(failure_list, columns=[\"Turbine_ID\", \"Timestamp\", target_name])\r\n",
                "    return failure_df\r\n",
                "\r\n",
                "failure_df_class  = create_failure_list()\r\n",
                "#Der Feature-Datensatz wird mit den Labels zusammengeführt. Dabei ist besonders wichtig, dass der Bezug zu der jeweiligen Turbine bestehen bleibt.\r\n",
                "labeled_df = pd.merge(merged_df, failure_df_class, on=[\"Turbine_ID\", \"Timestamp\"], how=\"left\");\r\n",
                "labeled_df = labeled_df.reset_index(drop=True)"
            ],
            "metadata": {
                "azdata_cell_guid": "c6ed3252-b028-4215-9e7e-9ea614374f9c",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "def create_failure_list(classes: list[str], days_per_class: int, target_name: str) -> pd.DataFrame:\r\n",
                "    days_lookback = len(classes) * days_per_class\r\n",
                "    ten_mins_of_n_days = int(24 * 60 * days_lookback / 10)\r\n",
                "    failure_list = []\r\n",
                "    for i, failure in enumerate(failures_gearbox):\r\n",
                "        turbine_id = str(failures_gearbox[\"Turbine_ID\"][i])\r\n",
                "        failure_ts = str(failures_gearbox[\"Timestamp\"][i])\r\n",
                "        failure_datetime = datetime.fromisoformat(failure_ts)\r\n",
                "        rounded_datetime = convert_round_minute_to_time(failure_datetime)\r\n",
                "        for iterator, current_class in enumerate(classes):\r\n",
                "            for j in range(ten_mins_of_n_days):\r\n",
                "                delta = timedelta(minutes=j*10)\r\n",
                "                # Prüfen ob obere und untere Schranke passen.\r\n",
                "                is_in_class = delta >= timedelta(days=iterator*days_per_class) and delta < timedelta(days=(iterator+1) * days_per_class)\r\n",
                "                if (is_in_class):\r\n",
                "                    new_datetime = rounded_datetime - delta\r\n",
                "                    datetime_formated = new_datetime.replace(tzinfo=timezone.utc)\r\n",
                "                    failure_list.append([turbine_id, datetime_formated.isoformat(), current_class])\r\n",
                "    \r\n",
                "    failure_df = pd.DataFrame(failure_list, columns=[\"Turbine_ID\", \"Timestamp\", target_name])\r\n",
                "\r\n",
                "    return failure_df\r\n",
                "\r\n",
                "class_target_name = \"Risk Level\"\r\n",
                "risk_levels = [\"low\", \"high\", \"med-high\", \"medium\", \"low-med\"]\r\n",
                "days_per_class = 18\r\n",
                "\r\n",
                "failure_df_multiclass = create_failure_list(classes=risk_levels, days_per_class=days_per_class, target_name=class_target_name)\r\n",
                "labeled_df = pd.merge(labeled_df, failure_df_multiclass, on=[\"Turbine_ID\", \"Timestamp\"], how=\"left\"); \r\n",
                "labeled_df = labeled_df.reset_index(drop=True)"
            ],
            "metadata": {
                "azdata_cell_guid": "a9b19440-d741-4c38-9b07-ae6f282405fd",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "labeled_df[class_target_name].fillna(\"low\", inplace = True)\r\n",
                "labeled_df[target_name].fillna(90, inplace = True)"
            ],
            "metadata": {
                "azdata_cell_guid": "dd5c5352-6698-4713-814f-0eaeb8c59c69",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "labeled_df[target_name].value_counts()"
            ],
            "metadata": {
                "azdata_cell_guid": "37849cb2-7c0a-4aff-be0c-9eeec8da6f85",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "# Alle Daten ab August 2017 liegen im Testset\r\n",
                "split_criterion_reg = labeled_df[\"Timestamp\"] >= \"2017-08-00T00:00:00+00:00\"\r\n",
                "\r\n",
                "test_gearbox = labeled_df[split_criterion_reg].reset_index(drop=True)#.iloc[:100].reset_index(drop=True)\r\n",
                "train_gearbox = labeled_df[~split_criterion_reg].reset_index(drop=True)#.iloc[:100].reset_index(drop=True)"
            ],
            "metadata": {
                "azdata_cell_guid": "a4918270-51b4-47b8-90d5-4f44746b2da9",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#Helper functions\r\n",
                "def getNextIdForTable(context, table_name):\r\n",
                "    table = context[\"base\"].classes[table_name]\r\n",
                "    return context[\"session\"].query(table.id).count() + 1\r\n",
                "\r\n",
                "def create_object(context, table_name, **kwargs):\r\n",
                "    mapped_class = context[\"base\"].classes[table_name]\r\n",
                "    obj = mapped_class()\r\n",
                "    #setattr(obj, \"id\", getNextIdForTable(context, table_name))\r\n",
                "    for key, value in kwargs.items():\r\n",
                "        setattr(obj, key, value)\r\n",
                "    context[\"session\"].add(obj)\r\n",
                "    context[\"session\"].commit()\r\n",
                "    return obj\r\n",
                "\r\n",
                "def update_values(obj, ref_class, session, **kwargs):\r\n",
                "    #clone = ref_class()\r\n",
                "    for column in ref_class.__table__.columns:\r\n",
                "        if(column.name in kwargs):\r\n",
                "            setattr(obj, column.name, kwargs[column.name])\r\n",
                "        #else:\r\n",
                "            #setattr(clone, column.name, getattr(obj, column.name))\r\n",
                "    #session.delete(obj)\r\n",
                "    #session.add(clone)\r\n",
                "    session.commit() \r\n",
                "    return obj\r\n",
                "def get_feature_id_by_name(Base, name):\r\n",
                "    query = session.query(metadata.tables[\"feature\"])\r\n",
                "    df = pd.DataFrame()\r\n",
                "    for batch in pd.read_sql_query(query.statement, engine, chunksize= 5):\r\n",
                "        df = pd.concat([df, batch], ignore_index=True)\r\n",
                "    for index, row in df.iterrows():\r\n",
                "        if(row[\"name\"]==name):\r\n",
                "            return row[\"id\"]\r\n",
                "  \r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "85ae35e6-d62d-4584-8137-80c4bb8b2b51",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#SQLAlchemy Setup\r\n",
                "def get_engine():\r\n",
                "    SERVER = 'localhost'\r\n",
                "    DATABASE = 'metmast'\r\n",
                "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect=DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};Trusted_Connection=yes;TrustServerCertificate=yes;')\r\n",
                "    return engine\r\n",
                "\r\n",
                "engine = get_engine()\r\n",
                "metadata = MetaData()\r\n",
                "metadata.reflect(bind=engine)\r\n",
                "Base = automap_base(metadata=metadata)\r\n",
                "Base.prepare(autoload_with=engine)\r\n",
                "mapper_registry = registry()"
            ],
            "metadata": {
                "azdata_cell_guid": "5caef074-47b6-4cc3-b026-44f2309ff28c",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "print(train_gearbox.columns)"
            ],
            "metadata": {
                "azdata_cell_guid": "4b19cd84-21a7-4bcb-93e4-f3b25eb765ca",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "context = dict()\r\n",
                "context[\"base\"] = Base\r\n",
                "context[\"session\"] = Session(bind=engine)\r\n",
                "\r\n",
                "if(getNextIdForTable(context, \"data_meta\")==1):\r\n",
                "    data_meta = create_object(context, \"data_meta\")\r\n",
                "\r\n",
                "groupings = [\"train\", \"test\"]\r\n",
                "grouping_ids = dict()\r\n",
                "if(getNextIdForTable(context, \"datapoint_mappings\")<len(groupings)):\r\n",
                "    for i, grouping_val in enumerate(groupings):\r\n",
                "        create_object(context, \"datapoint_mappings\",\r\n",
                "            data_meta_id = 1,\r\n",
                "            grouping = grouping_val\r\n",
                "        )\r\n",
                "for i, grouping_val in enumerate(groupings):\r\n",
                "    grouping_ids[grouping_val] = i + 1\r\n",
                "\r\n",
                "label_names = [\"Class\", \"Risk Level\"]\r\n",
                "label_ids = dict()\r\n",
                "if(getNextIdForTable(context, \"label\")<len(label_names)):\r\n",
                "    for i, label in enumerate(label_names):\r\n",
                "        create_object(context, \"label\",\r\n",
                "            data_meta_id = 1,\r\n",
                "            name = label,\r\n",
                "            description = \"TBD\"\r\n",
                "        )\r\n",
                "for i, name in enumerate(label_names):\r\n",
                "    label_ids[name] = i + 1\r\n",
                "\r\n",
                "meta_info_names = [\"Turbine_ID\", \"Timestamp\"]\r\n",
                "feature_names = [feature for feature in train_gearbox.columns if feature not in label_names and feature not in meta_info_names]\r\n",
                "aggregated_meta_feature_list = meta_info_names + feature_names\r\n",
                "aggregated_meta_feature_list = [feature for feature in aggregated_meta_feature_list if feature!=\"internal_string_102412\"]\r\n",
                "feature_ids = dict()\r\n",
                "meta_info_ids = dict()\r\n",
                "if(getNextIdForTable(context, \"feature\")<len(aggregated_meta_feature_list)):\r\n",
                "    for i, name in enumerate(aggregated_meta_feature_list):\r\n",
                "        type_ = \"data\"\r\n",
                "        if name in meta_info_names:\r\n",
                "            type_ = \"meta\"\r\n",
                "        create_object(context, \"feature\",\r\n",
                "            data_meta_id = 1,\r\n",
                "            name = name,\r\n",
                "            type_ = type_,\r\n",
                "            description = \"TBD\"\r\n",
                "        )\r\n",
                "for i, name in enumerate(aggregated_meta_feature_list):\r\n",
                "    if name in meta_info_ids:\r\n",
                "        meta_info_ids[name] = i + 1\r\n",
                "    else:\r\n",
                "        feature_ids[name] = i + 1\r\n",
                "aggregated_meta_feature_ids = {**feature_ids, **meta_info_ids}\r\n",
                "\r\n",
                "train_gearbox[\"internal_string_102412\"] = \"train\"\r\n",
                "test_gearbox[\"internal_string_102412\"] = \"test\"\r\n",
                "data = pd.concat([train_gearbox, test_gearbox], axis = 0)\r\n",
                "helper_string_row_index = data.columns.get_loc(\"internal_string_102412\")\r\n",
                "if(getNextIdForTable(context, \"datapoint\")<2):    \r\n",
                "    for i, row in enumerate(data.iterrows()):\r\n",
                "        _, row = row  \r\n",
                "        datapoint = create_object(context, \"datapoint\",\r\n",
                "            datapoint_mappings_id = grouping_ids[row[helper_string_row_index]]\r\n",
                "        )\r\n",
                "        for key, value in row.items():\r\n",
                "            if(key not in label_names and key!=\"internal_string_102412\"):\r\n",
                "                if \"float\" in str(type(value)):\r\n",
                "                    create_object(context, \"datapoint_feature_value_float\",\r\n",
                "                        datapoint_id = datapoint.id,\r\n",
                "                        feature_id = aggregated_meta_feature_ids[key],\r\n",
                "                        float_ = float(value)\r\n",
                "                    )\r\n",
                "                elif \"int\" in str(type(value)):\r\n",
                "                    create_object(context, \"datapoint_feature_value_int\",\r\n",
                "                        datapoint_id = datapoint.id,\r\n",
                "                        feature_id = aggregated_meta_feature_ids[key],\r\n",
                "                        int_ = int(value)\r\n",
                "                    )\r\n",
                "                else: #\"string\" in str(type(value)):\r\n",
                "                    create_object(context, \"datapoint_feature_value_string\",\r\n",
                "                        datapoint_id = datapoint.id,\r\n",
                "                        feature_id = aggregated_meta_feature_ids[key],\r\n",
                "                        string_ = str(value) \r\n",
                "                    )\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "8cc317eb-b006-40fe-ac77-fdcc1f061711",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "aggregated_meta_feature_ids"
            ],
            "metadata": {
                "azdata_cell_guid": "604b785c-9816-4778-8987-2ebc77812acb",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "data.columns"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "ce1864fa-8810-4797-812c-7e625734d595"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "for key, value in train_gearbox.iloc[0].items():\r\n",
                "    print(str(key) + \": \" + str(type(value)))"
            ],
            "metadata": {
                "azdata_cell_guid": "07d067d3-a917-41eb-8e72-737c2d8fab86",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}