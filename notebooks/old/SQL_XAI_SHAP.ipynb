{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pyodbc\n",
    "from sqlalchemy import Column, Date, Integer, String, Numeric, create_engine, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, ForeignKey, LargeBinary\n",
    "from sqlalchemy.orm import mapper, registry, Session\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import create_engine, func, MetaData, Table\n",
    "from sqlalchemy import create_engine, func, MetaData, Table, select, Column, Integer, String\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, balanced_accuracy_score \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sqlalchemy import inspect\n",
    "import scipy\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sqlalchemy.orm import relationship\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pyodbc\n",
    "from sqlalchemy import Column, Date, Integer, String, Numeric, create_engine, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, ForeignKey, func\n",
    "from sqlalchemy.orm import mapper, registry, Session\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pyodbc\n",
    "from sqlalchemy import Column, Date, Integer, String, Numeric, create_engine, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, ForeignKey, LargeBinary\n",
    "from sqlalchemy.orm import mapper, registry, Session\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import create_engine, func, MetaData, Table\n",
    "from sqlalchemy import create_engine, func, MetaData, Table, select, Column, Integer, String\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, balanced_accuracy_score \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sqlalchemy import inspect\n",
    "import scipy\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQLAlchemy Setup\n",
    "def get_engine():\n",
    "    SERVER = 'localhost'\n",
    "    DATABASE = 'metmast'\n",
    "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect=DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};Trusted_Connection=yes;TrustServerCertificate=yes;')\n",
    "    return engine\n",
    "\n",
    "engine = get_engine()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "Base = automap_base(metadata=metadata)\n",
    "Base.prepare(autoload_with=engine)\n",
    "mapper_registry = registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Trainingsdata\n",
    "def loadData(tableName):\n",
    "    # Get the train_data table\n",
    "    table = Table(tableName, metadata)\n",
    "    session = Session(bind=engine)    \n",
    "    batch_size = 500\n",
    "    query = session.query(table)\n",
    "    #Load Query into Dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for batch in pd.read_sql_query(query.statement, engine, chunksize=batch_size):\n",
    "        df = pd.concat([df, batch], ignore_index=True)\n",
    "        excluded_columns=[\"id\"]\n",
    "        if excluded_columns:\n",
    "            df = df.drop(columns=excluded_columns)    \n",
    "    return df\n",
    "\n",
    "train_X = loadData(\"train_data\")\n",
    "train_y = loadData(\"train_data_label\").drop(columns=[\"train_data_id\", \"Class\"]) \n",
    "test_X = loadData(\"test_data\")\n",
    "test_y = loadData(\"test_data_label\").drop(columns=[\"test_data_id\", \"Class\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Preset\n",
    "session = Session(bind=engine)  \n",
    "query = session.query(metadata.tables[\"hyperparameter\"])\n",
    "paras = pd.read_sql_query(query.statement, engine, chunksize=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeClassifier(\n",
    "        max_depth = args[\"max_depth\"],\n",
    "        min_samples_leaf = args[\"min_samples_leaf\"],\n",
    "        random_state = args[\"random_state\"],\n",
    "        max_features = args[\"max_features\"],\n",
    "        criterion = args[\"criterion\"],\n",
    "        #normalize = args[\"normalize\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods\n",
    "def update_values(obj, ref_class, session, **kwargs):\n",
    "    #clone = ref_class()\n",
    "    for column in ref_class.__table__.columns:\n",
    "        if(column.name in kwargs):\n",
    "            setattr(obj, column.name, kwargs[column.name])\n",
    "        #else:\n",
    "            #setattr(clone, column.name, getattr(obj, column.name))\n",
    "    #session.delete(obj)\n",
    "    #session.add(clone)\n",
    "    session.commit() \n",
    "    return obj\n",
    "def get_table_by_name(name):\n",
    "    inspector = inspect(engine)\n",
    "    return inspector.get_table(name)\n",
    "\n",
    "def get_feature_id_by_name(Base, name):\n",
    "    query = session.query(metadata.tables[\"feature\"])\n",
    "    df = pd.DataFrame()\n",
    "    for batch in pd.read_sql_query(query.statement, engine, chunksize= 5):\n",
    "        df = pd.concat([df, batch], ignore_index=True)\n",
    "    for index, row in df.iterrows():\n",
    "        if(row[\"name\"]==name):\n",
    "            return row[\"id\"]\n",
    "        \n",
    "def getNextIdForTable(Base, name):\n",
    "    table = Base.classes[name]\n",
    "    return session.query(table.id).count() + 1 \n",
    "  \n",
    "def create_object(Base, class_name, **kwargs):\n",
    "    mapped_class = Base.classes[class_name]\n",
    "    # Create an instance of the mapped class\n",
    "    obj = mapped_class()\n",
    "    # Set the object's attributes\n",
    "    for key, value in kwargs.items():\n",
    "        setattr(obj, key, value)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a561ff09736c45ea8c4c6a2f2879bc77e5e64e20329dfa0346a65d0599b7f690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
