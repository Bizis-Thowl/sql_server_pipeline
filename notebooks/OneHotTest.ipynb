{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "c3d05f7d-fb65-4e9f-a566-814f74338ed5",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "from NextVisionML import MLContext\n",
                "from NextVisionML import VarianceFilter, DecisionTreeClfr, OneHotClfr, PcaUnsupervised"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Create an context (Loads data)\n",
                "mlcontext = MLContext()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
                "from sklearn.metrics import balanced_accuracy_score\n",
                "import numpy as np\n",
                "from skorch import NeuralNetClassifier\n",
                "import skorch\n",
                "from sklearn.pipeline import Pipeline\n",
                "from NextVisionML.train.MLContext import MLContext\n",
                "from sklearn.base import BaseEstimator, TransformerMixin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleNetSoftmax(torch.nn.Module):\n",
                "    def __init__(self, input_size, output_size, layer_count):\n",
                "        super(SimpleNetSoftmax, self).__init__()\n",
                "        self.call_super_init\n",
                "        self.fc = torch.nn.ModuleList()\n",
                "        for _ in range(layer_count-1):\n",
                "            self.fc.append(torch.nn.Linear(input_size, input_size*2))\n",
                "            input_size*=2\n",
                "        self.fc.append(torch.nn.Linear(input_size, output_size))\n",
                "\n",
                "    def forward(self, X):\n",
                "        y = X\n",
                "        for layer in self.fc:\n",
                "            y = layer(y)\n",
                "        y = torch.softmax(y, dim=1)\n",
                "        return y\n",
                "\n",
                "class OneHotClfr(BaseEstimator, TransformerMixin):  \n",
                "  def __init__(self, mlcontext, args):\n",
                "    self.mlcontext = mlcontext\n",
                "    self.args = args\n",
                "    \n",
                "  def fit(self, X, y=None):\n",
                "    input_size = len(X.columns)\n",
                "    random_seed = 555555 #self.args[\"random_seed\"]    \n",
                "    self.num_classes = len(pd.unique(mlcontext.train_y[mlcontext.train_y.columns.values[0]]))\n",
                "    layer_count = 3 #args[\"layer_count\"]+2\n",
                "    num_epochs = 100 #args[\"num_epochs\"]\n",
                "    \n",
                "    train_X = torch.tensor(X.astype('float32').values)\n",
                "    min, _ = train_X.min(dim=0)\n",
                "    max, _ = train_X.max(dim=0)       \n",
                "    normalized_X = (train_X - min) / (max-min + 1)\n",
                "    normalized_X = normalized_X\n",
                "    \n",
                "    self.le = LabelEncoder()\n",
                "    y = self.le.fit_transform(y.values.ravel())\n",
                "    train_y = torch.tensor(y)\n",
                "    \n",
                "    one_hot_encoded = torch.nn.functional.one_hot(train_y.to(torch.int64), self.num_classes).float()\n",
                "    torch.manual_seed(random_seed)\n",
                "    self.net = SimpleNetSoftmax(input_size, self.num_classes, layer_count)\n",
                "    criterion = torch.nn.CrossEntropyLoss()\n",
                "    optimizer = torch.optim.SGD(self.net.parameters(), lr=0.005)\n",
                "\n",
                "    #Training loop\n",
                "    for _ in range(num_epochs):\n",
                "        outputs = self.net(normalized_X)\n",
                "        loss = criterion(outputs, one_hot_encoded)\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "    return self\n",
                "\n",
                "  def predict(self, X):\n",
                "    X = torch.tensor(X.astype('float32').values)\n",
                "    min, _ = X.min(dim=0)\n",
                "    max, _ = X.max(dim=0)       \n",
                "    normalized_X = (X - min) / (max-min + 1)\n",
                "    normalized_X = normalized_X  \n",
                "    \n",
                "    pred = self.net(normalized_X)\n",
                "    _, pred = torch.max(pred, 1)\n",
                "    pred = self.le.inverse_transform(pred)\n",
                "    return pred"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ohe = OneHotClfr(mlcontext, None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ohe.fit(mlcontext.train_X, mlcontext.train_y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pred = ohe.predict(mlcontext.test_X)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "balanced_accuracy_score(mlcontext.test_y, pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X= mlcontext.train_X\n",
                "y =mlcontext.train_y\n",
                "\n",
                "input_size = len(y.columns)\n",
                "random_seed = 0 #self.args[\"random_seed\"]    \n",
                "num_classes = len(pd.unique(mlcontext.train_y[mlcontext.train_y.columns.values[0]]))\n",
                "layer_count = 3 #args[\"layer_count\"]+2\n",
                "num_epochs = 5 #args[\"num_epochs\"]\n",
                "\n",
                "train_X = torch.tensor(X.astype('float32').values)\n",
                "min, _ = train_X.min(dim=0)\n",
                "max, _ = train_X.max(dim=0)       \n",
                "normalized_X = (train_X - min) / (max-min + 1)\n",
                "normalized_X = normalized_X"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "len(X.columns)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
